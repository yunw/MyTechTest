参考：http://it.sohu.com/20160906/n467840670.shtml

swarm cluster：
1、批量创建服务：
1.12引擎中多了docker service命令，和之前的docker run命令类似，但不同的是它能同时对多主机中的容器进行管理操作。下面就以1台manager节点，5台worker节点的swarm集群来阐述这些特性。
　　首先看下容器的创建：
　　$ docker network create -d overlay mynet
　　$ docker service create –replicas 3 –name frontend –network mynet –publish 80:80/tcp frontend_image:latest
　　$ docker service create –name redis –network mynet redis:latest
　　建立容器之前先创建一个overlay的网络，用来保证在不同主机上的容器网络互通的网络模式，后面两条命令用来在同一个名叫mynet的overlay网络里新建三个相同的web容器副本，和一个 redis副本，并且每个web容器都提供统一的端口映射关系。
2、集群容错：
既然是集群，当然难免会出现某几个节点故障的情况。当三个web副本中的其中两台web节点宕机后，cluster会根据自己的服务注册发现机制，以及之前设定的值–replicas 3，
在集群中剩余的空闲节点上，重新拉起两个web副本。不难看出，docker service其实不仅仅是批量启动服务这么简单，而是在集群中定义了一种状态。Cluster会持续检测服务的健康状态并维护集群的高可用性。
3、节点服务可扩展性：
Swarm Cluster不光只是提供了优秀的高可用性，同时也提供了节点弹性扩展的功能。当web这个容器组想动态扩展至六个节点个数时，只需执行$ docker service scale frontend=6就能立刻复制出三个新的副本出来。
眼尖的朋友可能注意到了，所有扩展出来的新web副本节点都run在原先的web节点下面，如果有需求想在每台节点上都run一个相同的副本有没有办法呢？答案也是肯定的：
　　$ docker service create –mode=global –name extend_frontend frontend_image:latest
　　一条命令分分钟搞定！
4、调度机制：
Docker1.12的调度机制也值得一提。
　　所谓的调度其主要功能是cluster的server端去选择在哪个服务器节点上创建并启动一个容器实例的动作。它是由一个装箱算法和过滤器组合而成。每次通过过滤器（constraint）启动容器的时候，
swarm cluster 都会调用调度机制筛选出匹配约束条件的服务器，并在这上面运行容器。
　　还是拿刚刚那个例子来说，再加上–constraint参数，就能指定容器只run在服务器硬盘是SSD的节点上（前提是加入到cluster的节点，在启动daemon时，本身需要加上参数 --label com.example.storage=”ssd”）:
　　$ docker service create –replicas 3 –name frontend –network mynet –publish 80:80/tcp –constraint engine.labels.com.example.storage=ssd frontend_image:lastest


一、安装docker engine
1、更新系统
yum update -y

#安装防火墙
yum install -y firewalld
systemctl start firewalld

2、添加repos：
tee /etc/yum.repos.d/docker.repo <<-'EOF'
[dockerrepo]
name=Docker Repository
baseurl=https://yum.dockerproject.org/repo/main/centos/7/
enabled=1
gpgcheck=1
gpgkey=https://yum.dockerproject.org/gpg
EOF

3、安装docker engine
yum install -y docker-engine

4、启动docker engine
systemctl start docker
systemctl enable docker

5、测试：
docker run hello-world

6、创建docker用户并赋root权限
useradd docker -g docker
chmod +w /etc/sudoers
vi /etc/sudoers
## Allow root to run any commands anywhere
root    ALL=(ALL)       ALL
docker  ALL=(ALL)       ALL    #添加这一行

chmod -w /etc/sudoers


二、卸载docker engine
[root@centos71 ~]# yum list installed | grep docker
Repository base is listed more than once in the configuration
Repository updates is listed more than once in the configuration
Repository extras is listed more than once in the configuration
Repository centosplus is listed more than once in the configuration
docker-engine.x86_64                 1.12.1-1.el7.centos             @dockerrepo
docker-engine-selinux.noarch         1.12.1-1.el7.centos             @dockerrepo

删除包：
yum -y remove docker-engine.x86_64
该命令不会删除images, containers, volumes, or user-created configuration files on your host
rm -rf /var/lib/docker  #delete all images, containers, and volumes
最后手动删除用户创建的配置文件。

三、swarm mode:
A、设置
1、准备三台主机
192.168.56.74 manager1   #管理节点
192.168.56.75 worker1    #工作节点
192.168.56.76 worker2    #工作节点

2、全部都安装docker engine，版本>=1.12

3、管理节点的ip必须是固定ip，应为swarm中的所有节点都需要和管理节点通信

4、开放端口：
tcp 2377：用于集群管理通信
tcp udp 7946：节点间通信
tcp udp 4789：overlay network通信
firewall-cmd --zone=public --add-port=2377/tcp --permanent
firewall-cmd --zone=public --add-port=4789/tcp --permanent
firewall-cmd --zone=public --add-port=4789/udp --permanent
firewall-cmd --zone=public --add-port=7946/tcp --permanent
firewall-cmd --zone=public --add-port=7946/udp --permanent
firewall-cmd --reload
firewall-cmd --permanent --query-port=2377/tcp
firewall-cmd --permanent --query-port=4789/tcp
firewall-cmd --permanent --query-port=4789/udp
firewall-cmd --permanent --query-port=7946/tcp
firewall-cmd --permanent --query-port=7946/udp
firewall-cmd --list-all

B、创建swarm
1、在管理节点上运行
#docker swarm init --advertise-addr <MANAGER-IP>
[root@manager1 ~]# docker swarm init --advertise-addr 192.168.56.74
Swarm initialized: current node (9twvez4pbmtf4gbghpo8bpmke) is now a manager.

To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-4a7ru7u0lmhubjkbo3e33njje8g8f1yc84g2pkg6frkk6r1y1t-8tuo211hz29no0h2d0gdg0weu \
    192.168.56.74:2377

To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
2、运行docker info查看swarm的状态：
[root@manager1 ~]# docker info
。。。。。。
Swarm: active
 NodeID: 9twvez4pbmtf4gbghpo8bpmke
 Is Manager: true
 ClusterID: 231c6fip4w9z9m4ie8nqnzjmx
 Managers: 1
 Nodes: 1
 Orchestration:
  Task History Retention Limit: 5
 Raft:
  Snapshot Interval: 10000
  Heartbeat Tick: 1
  Election Tick: 3
 Dispatcher:
  Heartbeat Period: 5 seconds
 CA Configuration:
  Expiry Duration: 3 months
 Node Address: 192.168.56.74
。。。。。。
3、运行docker node ls查看节点信息：
[root@manager1 ~]# docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
9twvez4pbmtf4gbghpo8bpmke *  manager1  Ready   Active        Leader
节点id后的*表示你当前正连在这个节点上

C、添加节点到swarm
1、添加worker1、worker2：
将创建manager1节点时显示的添加worker的命令在worker1节点上运行：
docker swarm join \
    --token SWMTKN-1-4a7ru7u0lmhubjkbo3e33njje8g8f1yc84g2pkg6frkk6r1y1t-8tuo211hz29no0h2d0gdg0weu \
    192.168.56.74:2377
注：如果上述信息找不到了可以在manager1上运行：
docker swarm join-token worker
[root@manager1 ~]# docker swarm join-token worker
To add a worker to this swarm, run the following command:

    docker swarm join \
    --token SWMTKN-1-4a7ru7u0lmhubjkbo3e33njje8g8f1yc84g2pkg6frkk6r1y1t-8tuo211hz29no0h2d0gdg0weu \
    192.168.56.74:2377
就可以看到命令了。

注：在添加worker的时候，发现worker的swarm状态一直是pendding，后来重启就好了。
[root@manager1 ~]# docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
1bis2jb2ahxdh1doqxcldqix6    worker2   Ready   Active        
9d4n3rrom73shvnt3ra9umnm8    worker1   Ready   Active        
9twvez4pbmtf4gbghpo8bpmke *  manager1  Ready   Active        Leader

D、部署服务到swarm：
在manager1节点上执行：
docker service create --replicas 1 --name helloworld alpine ping docker.com
docker service create创建一个服务
--name 指定服务名称
--replicas 指定运行的实例数量
alpine ping docker.com 容器执行的命令
查看正在运行的服务：
docker service ls
[root@manager1 ~]# docker service ls
ID            NAME        REPLICAS  IMAGE   COMMAND
7ta2fq9vk7g2  helloworld  1/1       alpine  ping docker.com

E、检查服务：
查看服务详情：
docker service inspect --pretty helloworld
[root@manager1 ~]# docker service inspect --pretty helloworld
ID:             7ta2fq9vk7g2ss50bhpqjv9sk
Name:           helloworld
Mode:           Replicated
 Replicas:      1
Placement:
UpdateConfig:
 Parallelism:   1
 On failure:    pause
ContainerSpec:
 Image:         alpine
 Args:          ping docker.com
Resources:

查看服务运行的节点：
docker service ps helloworld
[root@manager1 ~]# docker service ps helloworld
ID                         NAME          IMAGE   NODE      DESIRED STATE  CURRENT STATE          ERROR
6qfm26lul3b6qp19zygs8fw34  helloworld.1  alpine  manager1  Running        Running 4 minutes ago  

可以在运行task的节点上用docker ps命令查看相关容器的详情：
[root@manager1 ~]# docker ps
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
66b22e41d843        alpine:latest       "ping docker.com"   6 minutes ago       Up 6 minutes                            helloworld.1.6qfm26lul3b6qp19zygs8fw34

F、改变swarm中服务的数量：
在管理节点上执行：
docker service scale <SERVICE-ID>=<NUMBER-OF-TASKS>
例如：
docker service scale helloworld=5
[root@manager1 ~]# docker service scale helloworld=5
helloworld scaled to 5
[root@manager1 ~]# docker service ps helloworld
ID                         NAME          IMAGE   NODE      DESIRED STATE  CURRENT STATE                ERROR
6qfm26lul3b6qp19zygs8fw34  helloworld.1  alpine  manager1  Running        Running 28 minutes ago       
enay84c6jyoh46g0qz397a4w2  helloworld.2  alpine  worker1   Running        Preparing about an hour ago  
153qbyc4k59iw1665h2ywfmyw  helloworld.3  alpine  worker2   Running        Preparing about an hour ago  
9wcznb70esj6c8of2rm48gd30  helloworld.4  alpine  worker2   Running        Preparing about an hour ago  
9964c80mz4nawblhdhm4lpkem  helloworld.5  alpine  manager1  Running        Running 5 seconds ago

G、删除swarm上的服务：
docker service rm helloworld
[root@manager1 ~]# docker service rm helloworld
helloworld
[root@manager1 ~]# docker service inspect helloworld
[]
Error: no such service: helloworld
[root@manager1 ~]# docker service ps helloworld
Error: No such service: helloworld

H、滚动更新服务：
在管理节点上执行：
首先部署redis服务到swarm，配置更新延迟为10秒：
docker service create --replicas 3 --name redis --update-delay 10s redis:3.0.6
--update-delay 配置服务任务滚动更新的延迟时间，时间可以是s秒，m分，h小时，因此10m20s表示延迟10分20秒
默认调度器一次更新一个任务，可以用--update-parallelism来设置任务数量。
默认当一个任务更新后返回RUNNING状态，调度器才调度更新另一个任务，直到更新完毕。如果更新期间有任务返回FAILED，调度器将暂停更新。可以用--update-failure-action来
控制这种行为，在执行docker service create或docker service update命令的时候
[root@manager1 ~]# docker service create --replicas 3 --name redis --update-delay 10s redis:3.0.6
6nmewg9mcsmhnejp1j4sijs9b
[root@manager1 ~]# docker service inspect --pretty redis
ID:             6nmewg9mcsmhnejp1j4sijs9b
Name:           redis
Mode:           Replicated
 Replicas:      3
Placement:
UpdateConfig:
 Parallelism:   1
 Delay:         10s
 On failure:    pause
ContainerSpec:
 Image:         redis:3.0.6
Resources:

接下来进行滚动更新：
docker service update --image redis:3.0.7 redis
默认情况下，调度器按下面的步骤执行滚动更新：
停止第一个任务
更新停止的任务
启动更新后的任务
如果更新后的任务返回RUNNING，等待一个延迟时间然后停止另一个任务。
如果在更新期间，某个人物返回FAILED，暂停更新

[root@manager1 ~]# docker service update --image redis:3.0.7 redis
redis
[root@manager1 ~]# docker service inspect --pretty redis
ID:             6nmewg9mcsmhnejp1j4sijs9b
Name:           redis
Mode:           Replicated
 Replicas:      3
Update status:
 State:         updating
 Started:       8 seconds ago
 Message:       update in progress
Placement:
UpdateConfig:
 Parallelism:   1
 Delay:         10s
 On failure:    pause
ContainerSpec:
 Image:         redis:3.0.7
Resources:
[root@manager1 ~]# docker service ps redis
ID                         NAME         IMAGE        NODE      DESIRED STATE  CURRENT STATE               ERROR
9bi9o47666qn1emb2imipzf3v  redis.1      redis:3.0.6  manager1  Running        Running 32 seconds ago      
3eekg1h8vu50l5lx7yxjsao7t  redis.2      redis:3.0.7  manager1  Running        Preparing 17 seconds ago    
48zthq1koyqwjyd6sn9qol49z   \_ redis.2  redis:3.0.6  worker2   Shutdown       Shutdown about an hour ago  
btcro0yszkb4i2np61b1uqlwx  redis.3      redis:3.0.6  worker1   Running        Running about an hour ago  

注：在更新完成前，如果用docker service ps redis命令查看，可能会看到有些服务运行的是老版本，有的运行新版本。
更新完毕后的状态：
[root@manager1 ~]# docker service ps redis
ID                         NAME         IMAGE        NODE      DESIRED STATE  CURRENT STATE                ERROR
35wuxjb9daf2n5cqocuc9vzad  redis.1      redis:3.0.7  worker2   Running        Running about an hour ago    
9bi9o47666qn1emb2imipzf3v   \_ redis.1  redis:3.0.6  manager1  Shutdown       Shutdown about a minute ago  
3eekg1h8vu50l5lx7yxjsao7t  redis.2      redis:3.0.7  manager1  Running        Running 2 minutes ago        
48zthq1koyqwjyd6sn9qol49z   \_ redis.2  redis:3.0.6  worker2   Shutdown       Shutdown about an hour ago   
bxsgbbxd1al70myj5znz8h2oh  redis.3      redis:3.0.7  worker2   Running        Running about an hour ago    
btcro0yszkb4i2np61b1uqlwx   \_ redis.3  redis:3.0.6  worker1   Shutdown       Shutdown about an hour ago 


I、排干swarm中的一个节点：
有时希望对某个节点进行维护，此时管理者需要停止该节点上的任务，将副本任务发布到其它的正常节点上。
在管理节点上执行：
docker node update --availability drain <NODE-ID>
例如：
docker service ps redis
docker node update --availability drain worker2
docker node inspect --pretty worker2
docker service ps redis
[root@manager1 ~]# docker service ps redis
ID                         NAME         IMAGE        NODE      DESIRED STATE  CURRENT STATE               ERROR
35wuxjb9daf2n5cqocuc9vzad  redis.1      redis:3.0.7  worker2   Running        Running about an hour ago   
9bi9o47666qn1emb2imipzf3v   \_ redis.1  redis:3.0.6  manager1  Shutdown       Shutdown 12 minutes ago     
3eekg1h8vu50l5lx7yxjsao7t  redis.2      redis:3.0.7  manager1  Running        Running 12 minutes ago      
48zthq1koyqwjyd6sn9qol49z   \_ redis.2  redis:3.0.6  worker2   Shutdown       Shutdown about an hour ago  
bxsgbbxd1al70myj5znz8h2oh  redis.3      redis:3.0.7  worker2   Running        Running about an hour ago   
btcro0yszkb4i2np61b1uqlwx   \_ redis.3  redis:3.0.6  worker1   Shutdown       Shutdown about an hour ago  
[root@manager1 ~]# docker node update --availability drain worker2
worker2
[root@manager1 ~]# docker node inspect --pretty worker2
ID:                     1bis2jb2ahxdh1doqxcldqix6
Hostname:               worker2
Joined at:              2016-09-23 08:39:09.76350536 +0000 utc
Status:
 State:                 Ready
 Availability:          Drain
Platform:
 Operating System:      linux
 Architecture:          x86_64
Resources:
 CPUs:                  1
 Memory:                1.797 GiB
Plugins:
  Network:              bridge, host, null, overlay
  Volume:               local
Engine Version:         1.12.1 
[root@manager1 ~]# docker service ps redis
ID                         NAME         IMAGE        NODE      DESIRED STATE  CURRENT STATE                ERROR
83qvq0sgbh15vlnns0wqtn4io  redis.1      redis:3.0.7  worker1   Running        Preparing about an hour ago  
35wuxjb9daf2n5cqocuc9vzad   \_ redis.1  redis:3.0.7  worker2   Shutdown       Shutdown about an hour ago   
9bi9o47666qn1emb2imipzf3v   \_ redis.1  redis:3.0.6  manager1  Shutdown       Shutdown 13 minutes ago      
3eekg1h8vu50l5lx7yxjsao7t  redis.2      redis:3.0.7  manager1  Running        Running 13 minutes ago       
48zthq1koyqwjyd6sn9qol49z   \_ redis.2  redis:3.0.6  worker2   Shutdown       Shutdown about an hour ago   
avk4tl65g8rbmdnpmconm310j  redis.3      redis:3.0.7  worker1   Running        Preparing about an hour ago  
bxsgbbxd1al70myj5znz8h2oh   \_ redis.3  redis:3.0.7  worker2   Shutdown       Shutdown about an hour ago   
btcro0yszkb4i2np61b1uqlwx   \_ redis.3  redis:3.0.6  worker1   Shutdown       Shutdown about an hour ago  

回复active状态：
docker node update --availability active <NODE-ID>
例如：
docker node update --availability active worker2
docker node inspect --pretty worker2
[root@manager1 ~]# docker node update --availability active worker2
worker2
[root@manager1 ~]# docker node inspect --pretty worker2
ID:                     1bis2jb2ahxdh1doqxcldqix6
Hostname:               worker2
Joined at:              2016-09-23 08:39:09.76350536 +0000 utc
Status:
 State:                 Ready
 Availability:          Active
Platform:
 Operating System:      linux
 Architecture:          x86_64
Resources:
 CPUs:                  1
 Memory:                1.797 GiB
Plugins:
  Network:              bridge, host, null, overlay
  Volume:               local
Engine Version:         1.12.1
恢复active状态的节点又可以接受任务了（以下几种情况）：
服务更新规模的时候
滚动更新的时候
将另一个节点设置为Drain状态的时候
其他节点上的任务失败的时候


J、改变节点角色：
1、将worker变成manager：
docker node promote <node name>
例如：
docker node ls
docker node promote worker1
docker node ls
[root@manager1 ~]# docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
1bis2jb2ahxdh1doqxcldqix6    worker2   Ready   Active        
9d4n3rrom73shvnt3ra9umnm8    worker1   Ready   Active        
9twvez4pbmtf4gbghpo8bpmke *  manager1  Ready   Active        Leader
[root@manager1 ~]# docker node promote worker1
Node worker1 promoted to a manager in the swarm.
[root@manager1 ~]# docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
1bis2jb2ahxdh1doqxcldqix6    worker2   Ready   Active        
9d4n3rrom73shvnt3ra9umnm8    worker1   Ready   Active        Reachable
9twvez4pbmtf4gbghpo8bpmke *  manager1  Ready   Active        Leader

2、将manager变成worker：
docker node demote <node name>
例如：
docker node ls
docker node demote worker1
docker node ls
[root@manager1 ~]# docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
1bis2jb2ahxdh1doqxcldqix6    worker2   Ready   Active        
9d4n3rrom73shvnt3ra9umnm8    worker1   Ready   Active        Reachable
9twvez4pbmtf4gbghpo8bpmke *  manager1  Ready   Active        Leader
[root@manager1 ~]# docker node demote worker1
Manager worker1 demoted in the swarm.
[root@manager1 ~]# docker node ls
ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
1bis2jb2ahxdh1doqxcldqix6    worker2   Ready   Active        
9d4n3rrom73shvnt3ra9umnm8    worker1   Ready   Active        
9twvez4pbmtf4gbghpo8bpmke *  manager1  Ready   Active        Leader

为了利用swarm集群的容错特性，最好部署奇数台manager，在manager宕机数小于等于(n-1)/2台的时候，集群还是能正常运行的。
可以将manager的状态改为Drain，以便不在manager上部署服务。

K、服务怎样运行的：
当你创建一个服务，你就指定了哪个镜像将被使用，哪个命令将在容器内部被执行。你也定义了服务的一些选项：
端口：swarm将会使服务的端口在swarm外可见
覆盖网络（overlay network）：swarm内的服务通过覆盖网络相互通信
cpu、内存：预订与限制
滚动更新策略
运行的副本数量






































