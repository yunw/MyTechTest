安装：
curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.0.0-x86_64.rpm
sudo rpm -vi filebeat-5.0.0-x86_64.rpm

systemctl enable filebeat
systemctl start filebeat
systemctl status filebeat

配置：
vi /etc/filebeat/filebeat.yml
filebeat.prospectors:
- input_type: log
  paths:
    - /var/log/*.log
#-------------------------- Elasticsearch output ------------------------------
#output.elasticsearch:
  # Array of hosts to connect to.
  #hosts: ["192.168.56.76:9200"]
#----------------------------- Logstash output --------------------------------
output.logstash:
  # The Logstash hosts
  hosts: ["192.168.56.75:5044"]
  
注：registry_file默认在/usr/share/filebeat/bin/data目录下
  
测试配置：
[root@centos75 bin]# /usr/share/filebeat/bin/filebeat -configtest -path.config=/etc/filebeat -e
2016/11/07 02:00:57.231002 beat.go:264: INFO Home path: [/usr/share/filebeat/bin] Config path: [/etc/filebeat] Data path: [/usr/share/filebeat/bin/data] Logs path: [/usr/share/filebeat/bin/logs]
2016/11/07 02:00:57.231032 beat.go:174: INFO Setup Beat: filebeat; Version: 5.0.0
2016/11/07 02:00:57.231076 logstash.go:90: INFO Max Retries set to: 3
2016/11/07 02:00:57.231118 outputs.go:106: INFO Activated logstash as output plugin.
2016/11/07 02:00:57.231164 publish.go:291: INFO Publisher name: centos75
2016/11/07 02:00:57.231365 async.go:63: INFO Flush Interval set to: 1s
2016/11/07 02:00:57.231372 async.go:64: INFO Max Bulk Size set to: 2048
Config OK
  
  
配置filebeat：

Filebeat Prospectors Configuration：
sample config：
filebeat.prospectors:
- input_type: log
  paths:
    - /var/log/apache/httpd-*.log
  document_type: apache

- input_type: log
  paths:
    - /var/log/messages
    - /var/log/*.log
    
选项：
1、input_type：
log：读log file的每一行（默认）
stdin：读标准输入
2、paths：
将被爬取的路径列表。支持表达式。例如：/var/log/*/*.log。这个表达式将从/var/log的子目录爬取所有的.log文件，但是不爬取/var/log目录下的文件。
可以每行指定一个路径，每行都由一个连字符（-）开始。
3、encoding：
文件编码用于读取包含国际化字符的文件。
4、exclude_lines：
正则表达式列表，匹配那些你希望filebeat排除的行。
下面的配置删除所有以“DBG”开头的行：
filebeat.prospectors:
- paths:
    - /var/log/myapp/*.log
  exclude_lines: ['^DBG']
5、include_lines：
正则表达式列表，匹配你希望filebeat包含的行。
下面的配置将导出所有以“ERR”或“WARN”开始的行：
filebeat.prospectors:
- paths:
    - /var/log/myapp/*.log
  include_lines: ['^ERR', '^WARN']
备注：如果exclude_lines和include_lines都配置了，先解析include_lines，然后解析exclude_lines。
6、exclude_files：
正则表达式列表，匹配你希望filebeat忽略的文件。
下面的配置将忽略所有以.gz为扩展名的文件：
exclude_files: ['\.gz$']
7、tags：
tag列表，每个发布的事件中都包含tags字段。tags让kibana更容易选择特定的事件或者让logstash更容易进行条件过滤。
这些tag会被追加到通用配置的tag列表后面。
配置示例：
filebeat.prospectors:
- paths: ["/var/log/app/*.json"]
  tags: ["json"]
8、fields：
可选的fields可以让你在输出中加入附加的信息。例如，你可以加入fields让你可以用来过滤日志数据。
fields可以是标量值，数组，字典或者这些值得嵌套组合。默认情况下，在这里指定的fields将分组放在输出文档的一个fields子目录下。
如果要将自定义的fields保存为顶层fields，需要将fields_under_root选择设置为true。如果fields和通用配置重复，这里的值优先。
配置示例：
filebeat.prospectors:
- paths: ["/var/log/app/*.log"]
  fields:
    app_id: query_engine_12
9、fields_under_root：
设置为true，则用户自定义的fields将以顶层fields方式存储。
10、ignore_older
如果这个选项生效。filebeat将忽略修改时间在指定时间之前的文件。
可以使用字符串例如：2h 5m等等。默认为0，表示该选项无效。
备注：ignore_older的值必须比close_inactive的大。
这个设置影响的文件分两类：
a、从未被捕获的文件
b、捕获过，但是更新时间超过了ignore_older
从未被捕获过的文件被更新了，将从文件的开始开始读取，因为该文件的状态没有被持久化。以前被捕获过的文件，因为状态存在，当文件更新的时候，从最后的位置开始读取。
要从注册文件中删除以前捕获过的文件的状态，使用clean_inactive选项。
一个文件在被prospector忽略前，它必须被关闭。为了确保一个被忽略的文件不再被捕获，你必须将ignore_older设置得比close_inactive更大。
如果一个文件被捕获正处于ignore_older区间之内，捕获器将首先完成文件的读取，然后在close_inactive到达后关闭它。那么在那之后，这个文件将被忽略。
11、close_*
该配置选项用于在满足一定的标准或时间之后关闭捕获器。关闭捕获器意味着关闭文件句柄。如果一个文件在捕获器关闭之后更新了，在经过一个scan_frequency周期之后被重新拾起。
然而，如果在捕获器被关闭期间文件被移动或删除，filebeat将无法拾起该文件，任何捕获器没有读取的数据将丢失。
12、close_inactive
如果这个选项有效，那么一个文件在一个指定的时间内没有被捕获，filebeat将关闭该文件的句柄。时间的计数是以捕获器读取了最后一行数据后开始计算，而不是以文件最后修改时间为基础。
如果关闭的文件被更新，在经过一个scan_frequency周期之后，一个新的捕获器将开始并会拾起最新的数据。
建议将close_inactive设置为一个比你的日志文件更新的最小周期大的值。例如，如果日志文件几秒钟更新一次，那么可以安全的将close_inactive设置为1m。如果日志文件更新频率不固定，
可以使用多个prospector配置不同的值。
将close_inactive设置为一个很小的值意味着文件句柄很快就被关闭。然而，这有副作用，如果捕获器关闭了，新的日志行的发送就不是准实时了。
你可以用时间字符串例如2h 5m等。默认为5m




























1、定义你的log文件的路径：
filebeat.prospectors:
- input_type: log
  paths:
    - /var/log/*.log
    - /opt/log/*.log
    
2、定义输出日志的目的地：
a、输出到elasticsearch
output.elasticsearch:
  hosts: ["192.168.1.42:9200"]
b、输出到logstash
output.logstash:
  # The Logstash hosts
  hosts: ["192.168.56.75:5044"]
  
  
filebeat debug:
filebeat -e -d "*"
  
  
  
  
  
  
  
